{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_score, recall_score, confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'train_2v.csv' does not exist: b'train_2v.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6e3575ce4349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Import data & cursory inspection of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstrokedata_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_2v.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstrokedata_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_2v.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstrokedata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'train_2v.csv' does not exist: b'train_2v.csv'"
     ]
    }
   ],
   "source": [
    "#Import data & cursory inspection of data\n",
    "strokedata_train=pd.read_csv('train_2v.csv')\n",
    "strokedata_test=pd.read_csv('test_2v.csv')\n",
    "strokedata_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspecting and cleaning data.\n",
    "#drop id feature (not informative of stroke)\n",
    "strokedf_train=strokedata_train.drop('id',axis=1)\n",
    "strokedf_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strokedf_test=strokedata_test.drop('id',axis=1)\n",
    "strokedf_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect catagories within data to see nature of classifications and why count differences between features.\n",
    "print(strokedf_train['gender'].unique())\n",
    "print(strokedf_train['hypertension'].unique())\n",
    "print(strokedf_train['heart_disease'].unique())\n",
    "print(strokedf_train['ever_married'].unique())\n",
    "print(strokedf_train['work_type'].unique())\n",
    "print(strokedf_train['Residence_type'].unique())\n",
    "print(strokedf_train['smoking_status'].unique())\n",
    "print(strokedf_train['stroke'].unique())\n",
    "print(strokedf_train['age'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notced null values, searching for others.\n",
    "#identify number of null values in dataframe.\n",
    "strokedf_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deciding what to do with null features.\n",
    "#Identify how many of the features with null values are not null.\n",
    "print(\"BMI # avaliable (%):\"+str(len(strokedf_train)-1462) + '('+str((len(strokedf_train)-1462)/len(strokedf_train))+')')\n",
    "print(\"smoking # avaliable (%):\"+ str(len(strokedf_train)-13292) +'('+str((len(strokedf_train)-13292)/len(strokedf_train))+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considering removing entries with NULL bmi value (3% of data) or retaining.\n",
    "sns.boxplot(x='stroke', y='bmi', data=strokedf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect distribution of gender (Noticed \"Other\" classification).\n",
    "sns.countplot(strokedf_train['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Want to see \"Other\" contribution to data.\n",
    "strokedf_train['gender'].str.count(\"Other\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decide to remove \"Other\" from data on grounds that:\n",
    "#1) Paucity of data (11 values) thereby difficult to reliably predict relation to stroke using ML.\n",
    "#2) \"Other\" as a gender category in itself is ambiguous in that subject could be male to female, or female to male, or non-gender identifying. Thereby the potentialf or at least three different categories within that 11.\n",
    "#3) Difficulty finding scientific literature which inspects causation between not identifying as a male or female and stroke prevalance.\n",
    "strokedf_train = strokedf_train[strokedf_train['gender'] != \"Other\"]\n",
    "strokedf_test = strokedf_test[strokedf_test['gender'] != \"Other\"]\n",
    "sns.countplot(strokedf_train['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspecting distribution of other features with regards to stroke .\n",
    "sns.catplot(x='hypertension',kind='count',data=strokedf_train, hue='stroke', legend=False)\n",
    "plt.legend(loc='upper right', labels=['No-stroke', 'Stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='heart_disease',kind='count',hue='stroke', legend=False,data=strokedf_train)\n",
    "plt.legend(loc='upper right', labels=['No-stroke', 'Stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='ever_married',kind='count',hue='stroke', legend=False,data=strokedf_train)\n",
    "plt.legend(loc='upper right', labels=['No-stroke', 'Stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='work_type',kind='count',hue='stroke', legend=False,data=strokedf_train)\n",
    "plt.legend(loc='upper right', labels=['No-stroke', 'Stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Residence_type',kind='count',hue='stroke', legend=False,data=strokedf_train)\n",
    "plt.legend(loc='upper right', labels=['No-stroke', 'Stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='smoking_status',kind='count',hue='stroke', legend=False,data=strokedf_train)\n",
    "plt.legend(loc='upper right', labels=['No-stroke', 'Stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(strokedf_train.loc[strokedf_train['stroke']==0]['age'], label='No stroke',norm_hist=True, bins=20)\n",
    "sns.distplot(strokedf_train.loc[strokedf_train['stroke']==1]['age'], label='Stroke',norm_hist=True, bins=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decesion to remove samples with age less than 16 because:\n",
    "#1) Many of the features in the data are strictly dependent on age being over 16 (marriage, smoking, employment).\n",
    "#2) Research investigating causation between age and stroke typically omits ages under 15.\n",
    "#3) Science has demonstrated that genetic predisposition (e.g. sickle cell anemia), environment (e.g. carbon monoxide levels), and conginental conditions are related to stroke in children. \n",
    "#https://www.chp.edu/our-services/brain/neurology/stroke-program/causes-and-symptoms.\n",
    "strokedf_train = strokedf_train[strokedf_train['age'] > 16]\n",
    "strokedf_test = strokedf_test[strokedf_test['age'] > 16]\n",
    "sns.distplot(strokedf_train.loc[strokedf_train['stroke']==0]['age'], label='No stroke',norm_hist=True, bins=20)\n",
    "sns.distplot(strokedf_train.loc[strokedf_train['stroke']==1]['age'], label='Stroke',norm_hist=True, bins=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-uniform distribution of ages.\n",
    "#Considering grouping data by age.\n",
    "strokedf_train['age'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(strokedf_train.loc[strokedf_train['stroke']==0]['avg_glucose_level'], label='No stroke',norm_hist=True, bins=20)\n",
    "sns.distplot(strokedf_train.loc[strokedf_train['stroke']==1]['avg_glucose_level'], label='Stroke',norm_hist=True, bins=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data shows bimodal distribution for both stroke cases.\n",
    "#Considering grouping data by blood glucose risk groups.\n",
    "strokedf_train['avg_glucose_level'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(strokedf_train.loc[strokedf_train['stroke']==0]['bmi'], label='No stroke', norm_hist=True, bins=20)\n",
    "sns.distplot(strokedf_train.loc[strokedf_train['stroke']==1]['bmi'], label='Stroke', norm_hist=True, bins=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data slightly right skewed.\n",
    "#Considering organising BMI by groups.\n",
    "strokedf_train['bmi'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chose to retain BMI and replaced null values with median due to number of outliers.\n",
    "#Considered predicting BMI however do not possess metrics to explicitly calculate. \n",
    "#Consider possibility of predicting BMI using remaining data albeit may converge on predisposed bias in data.\n",
    "strokedf_train['bmi'].fillna(strokedf_train['bmi'].median(), inplace= True)\n",
    "strokedf_test['bmi'].fillna(strokedf_train['bmi'].median(), inplace= True)\n",
    "#Considering removing data with smoking status or replacing with unknown.\n",
    "#However null smoking status constitutes 30% of data.\n",
    "#Chose to retain and assign \"unknown\".\n",
    "strokedf_train['smoking_status'].fillna(value='unknown',inplace=True)\n",
    "strokedf_test['smoking_status'].fillna(value='unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if null values remain\n",
    "strokedf_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking values across dataframe\n",
    "strokedf_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paucity of data relating to stroke occurances, caution of potential overfitting to non-stroke due to imbalance in data.\n",
    "sns.countplot(strokedf_train['stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For building a decesion tree features need to be numerical\n",
    "enc=preprocessing.LabelEncoder()\n",
    "\n",
    "strokedf_train['gender'] = enc.fit_transform(strokedf_train['gender'])\n",
    "strokedf_train['ever_married'] = enc.fit_transform(strokedf_train['ever_married'])\n",
    "strokedf_train['work_type'] = enc.fit_transform(strokedf_train['work_type'])\n",
    "strokedf_train['Residence_type'] = enc.fit_transform(strokedf_train['Residence_type'])\n",
    "strokedf_train['smoking_status'] = enc.fit_transform(strokedf_train['smoking_status'])\n",
    "strokedf_test['gender'] = enc.fit_transform(strokedf_test['gender'])\n",
    "strokedf_test['ever_married'] = enc.fit_transform(strokedf_test['ever_married'])\n",
    "strokedf_test['work_type'] = enc.fit_transform(strokedf_test['work_type'])\n",
    "strokedf_test['Residence_type'] = enc.fit_transform(strokedf_test['Residence_type'])\n",
    "strokedf_test['smoking_status'] = enc.fit_transform(strokedf_test['smoking_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear imbalance in stroke data as mentioned earlier, going to address now before ML to mitigate overfitting.\n",
    "print(strokedf_train['stroke'].value_counts())\n",
    "#ros=RandomOverSampler(random_state=77)\n",
    "smote = SMOTE(random_state=77)\n",
    "#Use ROSE method\n",
    "X_resamp, y_resamp=smote.fit_resample(strokedf_train.loc[:,strokedf_train.columns!='stroke'],strokedf_train['stroke'])\n",
    "print(format(X_resamp.shape))\n",
    "print(format(y_resamp.shape))\n",
    "y_resamp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resamp, y_resamp, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and fit Logistic Regression model.\n",
    "LoRmod=LogisticRegression(max_iter=10000)\n",
    "LoRmod.fit(X_train,y_train)\n",
    "#Score LR training\n",
    "LoRmod.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict from manufactured test and score\n",
    "LoRpred= LoRmod.predict(X_test)\n",
    "print('Accuracy score:', accuracy_score(y_test,LoRpred)*100)\n",
    "print('F1 score:', f1_score(y_test, LoRpred)*100)\n",
    "print('Recall score:', recall_score(y_test, LoRpred)*100)\n",
    "print('Precision score:', precision_score(y_test, LoRpred)*100)\n",
    "print('Confusion matrix:', confusion_matrix(y_test, LoRpred))\n",
    "print('Classification report:', classification_report(y_test, LoRpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict stroke in case study using LoR.\n",
    "LoRprestest = LoRmod.predict(strokedf_test)\n",
    "LoRpred = pd.DataFrame(LoRprestest,columns=['prediction'])\n",
    "print(len(strokedf_test))\n",
    "LoRpred['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and fit Decesion tree model.\n",
    "DTmod=DecisionTreeClassifier(criterion='gini', random_state = 77,max_depth=10)\n",
    "DTmod.fit(X_train,y_train)\n",
    "#Score DT fit.\n",
    "DTmod.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict from manufactured test and score\n",
    "DTpred = DTmod.predict(X_test)\n",
    "print('Accuracy score:', accuracy_score(y_test,DTpred)*100)\n",
    "print('F1 score:', f1_score(y_test, DTpred)*100)\n",
    "print('Recall score:', recall_score(y_test, DTpred)*100)\n",
    "print('Precision score:', precision_score(y_test, DTpred)*100)\n",
    "print('Confusion matrix:', confusion_matrix(y_test, DTpred))\n",
    "print('Classification report:', classification_report(y_test, DTpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine how DT weighted features.\n",
    "featurelist=list(strokedf_train.columns[:])\n",
    "plt.bar(range(len(DTmod.feature_importances_)), DTmod.feature_importances_)\n",
    "plt.xlabel(\"feature\")\n",
    "plt.ylabel(\"importance\")\n",
    "plt.title(\"feature importance\")\n",
    "plt.xticks(range(len(DTmod.feature_importances_)), featurelist,rotation='vertical')\n",
    "plt.show()\n",
    "print(featurelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict stroke in case study using DT.\n",
    "DTprestest = DTmod.predict(strokedf_test)\n",
    "DTpredf = pd.DataFrame(DTprestest,columns=['prediction'])\n",
    "print(len(strokedf_test))\n",
    "DTpredf['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and fit Random Forest model.\n",
    "RFmod=RandomForestClassifier(n_estimators=100,random_state=77)\n",
    "RFmod.fit(X_train,y_train)\n",
    "#Score RF fit.\n",
    "RFmod.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict from manufactured test and score\n",
    "RFpred = RFmod.predict(X_test)\n",
    "print('Accuracy score:', accuracy_score(y_test,RFpred)*100)\n",
    "print('F1 score:', f1_score(y_test, RFpred)*100)\n",
    "print('Recall score:', recall_score(y_test, RFpred)*100)\n",
    "print('Precision score:', precision_score(y_test, RFpred)*100)\n",
    "print('Confusion matrix:', confusion_matrix(y_test, RFpred))\n",
    "print('Classification report:', classification_report(y_test, RFpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine how RF weighted features.\n",
    "featurelist=list(strokedf_train.columns[:])\n",
    "plt.bar(range(len(RFmod.feature_importances_)), RFmod.feature_importances_)\n",
    "plt.xlabel(\"feature\")\n",
    "plt.ylabel(\"importance\")\n",
    "plt.title(\"feature importance\")\n",
    "plt.xticks(range(len(RFmod.feature_importances_)), featurelist,rotation='vertical')\n",
    "plt.show()\n",
    "print(featurelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict stroke in case study using RF.\n",
    "RFprestest = RFmod.predict(strokedf_test)\n",
    "RFpredf = pd.DataFrame(RFprestest,columns=['prediction'])\n",
    "print(len(strokedf_test))\n",
    "RFpredf['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=77)\n",
    "cv_LoR = model_selection.cross_val_score(LogisticRegression(max_iter=10000), X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "cv_DT = model_selection.cross_val_score(DecisionTreeClassifier(criterion='gini', random_state = 77,max_depth=11), X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "cv_RF = model_selection.cross_val_score(RandomForestClassifier(n_estimators=100), X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "results=[cv_LoR,cv_DT,cv_RF]\n",
    "names=[\"LoR\",\"DT\",\"RF\"]\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Curated approach (v1), repeating cleaning from naive approach v1\n",
    "strokedatacur_train=pd.read_csv('train_2v.csv')\n",
    "strokedatacur_test=pd.read_csv('test_2v.csv')\n",
    "strokedatadfcur_train=strokedatacur_train.drop('id',axis=1)\n",
    "strokedatadfcur_test=strokedatacur_test.drop('id',axis=1)\n",
    "strokedatadfcur_train = strokedatadfcur_train[strokedatadfcur_train['gender'] != \"Other\"]\n",
    "strokedatadfcur_test = strokedatadfcur_test[strokedatadfcur_test['gender'] != \"Other\"]\n",
    "strokedatadfcur_train = strokedatadfcur_train[strokedatadfcur_train['age'] > 16]\n",
    "strokedatadfcur_test = strokedatadfcur_test[strokedatadfcur_test['age'] > 16]\n",
    "strokedatadfcur_train['bmi'].fillna(strokedatadfcur_train['bmi'].median(), inplace= True)\n",
    "strokedatadfcur_test['bmi'].fillna(strokedatadfcur_test['bmi'].median(), inplace= True)\n",
    "strokedatadfcur_train['smoking_status'].fillna(value='unknown',inplace=True)\n",
    "strokedatadfcur_test['smoking_status'].fillna(value='unknown',inplace=True)\n",
    "strokedatadfcur_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strokedatadfcur_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strokedatadfcur_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f6b7dc4b8108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstrokedatadfcur_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'strokedatadfcur_train' is not defined"
     ]
    }
   ],
   "source": [
    "strokedatadfcur_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Going to group age classes becase:\n",
    "#1) Distribution of ages as seen in earlier graph.\n",
    "#2) Literature indicates that stroke prevalance doubles every 10 years.\n",
    "strokedatadfcur_train['age']=strokedatadfcur_train['age'].apply(lambda x:\"16-24\" if 16<=x<25 else (\"25-34\" if 25<=x<35 else (\"35-44\" if 35<=x<44 else (\"45-54\" if 45<=x<54 else (\"55-64\" if 55<=x<64 else (\"65-74\" if 65<=x<74 else (\"75-84\" if 75<=x<84 else \"85+\")))))))\n",
    "strokedatadfcur_test['age']=strokedatadfcur_test['age'].apply(lambda x:\"16-24\" if 16<=x<25 else (\"25-34\" if 25<=x<35 else (\"35-44\" if 35<=x<44 else (\"45-54\" if 45<=x<54 else (\"55-64\" if 55<=x<64 else (\"65-74\" if 65<=x<74 else (\"75-84\" if 75<=x<84 else \"85+\")))))))\n",
    "#Going to group data by average glucose levels because:\n",
    "#1) Literaure on the subjective partitions the glucose levels after meals as grouped below.\n",
    "#2) While the distribution shows a clear bimodality I am curious how the model will perform.\n",
    "strokedatadfcur_train['avg_glucose_level']=strokedatadfcur_train['avg_glucose_level'].apply(lambda x:\"healthy\" if x<140 else (\"pre-diabetes\" if 140<=x<200 else \"diabetes\"))\n",
    "strokedatadfcur_test['avg_glucose_level']=strokedatadfcur_test['avg_glucose_level'].apply(lambda x:\"healthy\" if x<140 else (\"pre-diabetes\" if 140<=x<200 else \"diabetes\"))\n",
    "#Going to group data by average glucose levels because:\n",
    "#1) Literaure on the subjective partitions the BMI as grouped below.\n",
    "#2) While the distribution shows only a slight right skewness perhaps redistributing as below will introduce symmetry to the distribution.\n",
    "#3) I am curious on how it will perform.\n",
    "strokedatadfcur_train['bmi']=strokedatadfcur_train['bmi'].apply(lambda x:\"<20\" if x<20 else (\"20-22\" if 20<=x<23 else (\"23-24\" if 23<=x<25 else (\"25-26\" if 25<=x<27 else (\"27-29\" if 27<=x<30 else (\"30-34\" if 30<=x<35 else \"35+\"))))))\n",
    "strokedatadfcur_test['bmi']=strokedatadfcur_test['bmi'].apply(lambda x:\"<20\" if x<20 else (\"20-22\" if 20<=x<23 else (\"23-24\" if 23<=x<25 else (\"25-26\" if 25<=x<27 else (\"27-29\" if 27<=x<30 else (\"30-34\" if 30<=x<35 else \"35+\"))))))\n",
    "strokedatadfcur_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='age',kind='count',col='stroke',data=strokedatadfcur_train, order=['16-24','25-34','35-44','45-54','55-64','65-74','75-84','85+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='avg_glucose_level',kind='count',col='stroke',data=strokedatadfcur_train,  order=['healthy','pre-diabetes', 'diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='bmi',kind='count',col='stroke',data=strokedatadfcur_train,  order=['<20','20-22', '23-24','25-26','27-29','30-34','35+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding data\n",
    "strokedatadfcur_train['gender'] = enc.fit_transform(strokedatadfcur_train['gender'])\n",
    "strokedatadfcur_train['ever_married'] = enc.fit_transform(strokedatadfcur_train['ever_married'])\n",
    "strokedatadfcur_train['work_type'] = enc.fit_transform(strokedatadfcur_train['work_type'])\n",
    "strokedatadfcur_train['Residence_type'] = enc.fit_transform(strokedatadfcur_train['Residence_type'])\n",
    "strokedatadfcur_train['smoking_status'] = enc.fit_transform(strokedatadfcur_train['smoking_status'])\n",
    "strokedatadfcur_train['age'] = enc.fit_transform(strokedatadfcur_train['age'])\n",
    "strokedatadfcur_train['bmi'] = enc.fit_transform(strokedatadfcur_train['bmi'])\n",
    "strokedatadfcur_train['avg_glucose_level'] = enc.fit_transform(strokedatadfcur_train['avg_glucose_level'])\n",
    "strokedatadfcur_test['gender'] = enc.fit_transform(strokedf_test['gender'])\n",
    "strokedatadfcur_test['ever_married'] = enc.fit_transform(strokedatadfcur_test['ever_married'])\n",
    "strokedatadfcur_test['work_type'] = enc.fit_transform(strokedatadfcur_test['work_type'])\n",
    "strokedatadfcur_test['Residence_type'] = enc.fit_transform(strokedatadfcur_test['Residence_type'])\n",
    "strokedatadfcur_test['smoking_status'] = enc.fit_transform(strokedatadfcur_test['smoking_status'])\n",
    "strokedatadfcur_test['age'] = enc.fit_transform(strokedatadfcur_test['age'])\n",
    "strokedatadfcur_test['bmi'] = enc.fit_transform(strokedatadfcur_test['bmi'])\n",
    "strokedatadfcur_test['avg_glucose_level'] = enc.fit_transform(strokedatadfcur_test['avg_glucose_level'])\n",
    "\n",
    "#Resampling data (as described earlier)\n",
    "X_resampcur, y_resampcur=smote.fit_resample(strokedatadfcur_train.loc[:,strokedatadfcur_train.columns!='stroke'],strokedatadfcur_train['stroke'])\n",
    "print(format(X_resampcur.shape))\n",
    "print(format(y_resampcur.shape))\n",
    "y_resamp.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traincur, X_testcur, y_traincur, y_testcur = train_test_split(X_resampcur, y_resampcur, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmod=RandomForestClassifier(n_estimators=100,random_state=77)\n",
    "RFmod.fit(X_traincur,y_traincur)\n",
    "RFmod.score(X_traincur,y_traincur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFpred = RFmod.predict(X_testcur)\n",
    "print('Accuracy score:', accuracy_score(y_testcur,RFpred)*100)\n",
    "print('F1 score:', f1_score(y_testcur, RFpred)*100)\n",
    "print('Recall score:', recall_score(y_testcur, RFpred)*100)\n",
    "print('Precision score:', precision_score(y_testcur, RFpred)*100)\n",
    "print('Confusion matrix:', confusion_matrix(y_testcur, RFpred))\n",
    "print('Classification report:', classification_report(y_testcur, RFpred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurelist=list(strokedatadfcur_train.columns[:])\n",
    "plt.bar(range(len(RFmod.feature_importances_)), RFmod.feature_importances_)\n",
    "plt.xlabel(\"feature\")\n",
    "plt.ylabel(\"importance\")\n",
    "plt.title(\"feature importance\")\n",
    "plt.xticks(range(len(RFmod.feature_importances_)), featurelist,rotation='vertical')\n",
    "plt.show()\n",
    "print(featurelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFprestest = RFmod.predict(strokedatadfcur_test)\n",
    "RFpredf = pd.DataFrame(RFprestest,columns=['prediction'])\n",
    "print(len(strokedatadfcur_test))\n",
    "RFpredf['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Curated approach v2, repeating cleaning from curatved v1 with exceptions\n",
    "strokedatacur_train=pd.read_csv('train_2v.csv')\n",
    "strokedatacur_test=pd.read_csv('test_2v.csv')\n",
    "strokedatadfcur_train=strokedatacur_train.drop('id',axis=1)\n",
    "strokedatadfcur_test=strokedatacur_test.drop('id',axis=1)\n",
    "strokedatadfcur_train = strokedatadfcur_train[strokedatadfcur_train['gender'] != \"Other\"]\n",
    "strokedatadfcur_test = strokedatadfcur_test[strokedatadfcur_test['gender'] != \"Other\"]\n",
    "strokedatadfcur_train = strokedatadfcur_train[strokedatadfcur_train['age'] > 16]\n",
    "strokedatadfcur_test = strokedatadfcur_test[strokedatadfcur_test['age'] > 16]\n",
    "strokedatadfcur_train['bmi'].fillna(strokedatadfcur_train['bmi'].median(), inplace= True)\n",
    "strokedatadfcur_test['bmi'].fillna(strokedatadfcur_test['bmi'].median(), inplace= True)\n",
    "strokedatadfcur_train['smoking_status'].fillna(value='unknown',inplace=True)\n",
    "strokedatadfcur_test['smoking_status'].fillna(value='unknown',inplace=True)\n",
    "strokedatadfcur_train['age']=strokedatadfcur_train['age'].apply(lambda x:\"16-24\" if 16<=x<25 else (\"25-34\" if 25<=x<35 else (\"35-44\" if 35<=x<44 else (\"45-54\" if 45<=x<54 else (\"55-64\" if 55<=x<64 else (\"65-74\" if 65<=x<74 else (\"75-84\" if 75<=x<84 else \"85+\")))))))\n",
    "strokedatadfcur_test['age']=strokedatadfcur_test['age'].apply(lambda x:\"16-24\" if 16<=x<25 else (\"25-34\" if 25<=x<35 else (\"35-44\" if 35<=x<44 else (\"45-54\" if 45<=x<54 else (\"55-64\" if 55<=x<64 else (\"65-74\" if 65<=x<74 else (\"75-84\" if 75<=x<84 else \"85+\")))))))\n",
    "strokedatadfcur_train['gender'] = enc.fit_transform(strokedatadfcur_train['gender'])\n",
    "strokedatadfcur_train['ever_married'] = enc.fit_transform(strokedatadfcur_train['ever_married'])\n",
    "strokedatadfcur_train['work_type'] = enc.fit_transform(strokedatadfcur_train['work_type'])\n",
    "strokedatadfcur_train['Residence_type'] = enc.fit_transform(strokedatadfcur_train['Residence_type'])\n",
    "strokedatadfcur_train['smoking_status'] = enc.fit_transform(strokedatadfcur_train['smoking_status'])\n",
    "strokedatadfcur_train['age'] = enc.fit_transform(strokedatadfcur_train['age'])\n",
    "strokedatadfcur_test['gender'] = enc.fit_transform(strokedf_test['gender'])\n",
    "strokedatadfcur_test['ever_married'] = enc.fit_transform(strokedatadfcur_test['ever_married'])\n",
    "strokedatadfcur_test['work_type'] = enc.fit_transform(strokedatadfcur_test['work_type'])\n",
    "strokedatadfcur_test['Residence_type'] = enc.fit_transform(strokedatadfcur_test['Residence_type'])\n",
    "strokedatadfcur_test['smoking_status'] = enc.fit_transform(strokedatadfcur_test['smoking_status'])\n",
    "strokedatadfcur_test['age'] = enc.fit_transform(strokedatadfcur_test['age'])\n",
    "\n",
    "X_resampcur, y_resampcur=smote.fit_resample(strokedatadfcur_train.loc[:,strokedatadfcur_train.columns!='stroke'],strokedatadfcur_train['stroke'])\n",
    "print(format(X_resampcur.shape))\n",
    "print(format(y_resampcur.shape))\n",
    "y_resamp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strokedatadfcur_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traincur, X_testcur, y_traincur, y_testcur = train_test_split(X_resampcur, y_resampcur, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmod=RandomForestClassifier(n_estimators=100,random_state=77)\n",
    "RFmod.fit(X_traincur,y_traincur)\n",
    "RFmod.score(X_traincur,y_traincur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFpred = RFmod.predict(X_testcur)\n",
    "print('Accuracy score:', accuracy_score(y_testcur,RFpred)*100)\n",
    "print('F1 score:', f1_score(y_testcur, RFpred)*100)\n",
    "print('Recall score:', recall_score(y_testcur, RFpred)*100)\n",
    "print('Precision score:', precision_score(y_testcur, RFpred)*100)\n",
    "print('Confusion matrix:', confusion_matrix(y_testcur, RFpred))\n",
    "print('Classification report:', classification_report(y_testcur, RFpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurelist=list(strokedatadfcur_train.columns[:])\n",
    "plt.bar(range(len(RFmod.feature_importances_)), RFmod.feature_importances_)\n",
    "plt.xlabel(\"feature\")\n",
    "plt.ylabel(\"importance\")\n",
    "plt.title(\"feature importance\")\n",
    "plt.xticks(range(len(RFmod.feature_importances_)), featurelist,rotation='vertical')\n",
    "plt.show()\n",
    "print(featurelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFprestest = RFmod.predict(strokedatadfcur_test)\n",
    "RFpredf = pd.DataFrame(RFprestest,columns=['prediction'])\n",
    "print(len(strokedatadfcur_test))\n",
    "RFpredf['prediction'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
